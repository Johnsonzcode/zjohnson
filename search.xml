<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[gemma GWAS分析]]></title>
    <url>%2FGWAS%2Fgemma-GWAS%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[链接]]></content>
      <categories>
        <category>GWAS</category>
      </categories>
      <tags>
        <tag>全基因组关联分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R中做正态检验]]></title>
    <url>%2FR%2FR%E4%B8%AD%E5%81%9A%E6%AD%A3%E6%80%81%E6%A3%80%E9%AA%8C.html</url>
    <content type="text"><![CDATA[正态检验1正态检验2]]></content>
      <categories>
        <category>R</category>
      </categories>
      <tags>
        <tag>正态检验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[错误1923，请确认你有足够权限安装系统应用]]></title>
    <url>%2FPC%2F%E8%A7%A3%E5%86%B3office-2010%E6%9C%AA%E5%8D%B8%E8%BD%BD%E5%AE%8C%E5%85%A8%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[问题在安装Office2010全家桶后，想卸载不需要的部件，用的是Windows install clean up卸载，结果这软件是强制卸载，并不安全也不完善。造成其他部件也不能正常使用。不得已要重装。重装时遇上如题报错。 解决方案 下载MicrosoftFixit50450.msi来完全卸载office 重启 以管理员身份重装即可]]></content>
      <categories>
        <category>PC</category>
      </categories>
      <tags>
        <tag>PC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无损系统迁移]]></title>
    <url>%2FPC%2F%E6%97%A0%E6%8D%9F%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB.html</url>
    <content type="text"><![CDATA[前言老笔记本早就想升级了，也买好了多余的固态硬盘。昨天清灰总算逮到机会了。一起就安装上了，SATA3接口的影驰240G，180左右，三年换新，还可以。起码跟机械硬盘有质的区别。 症状通过系统迁移，将系统迁移到固态硬盘了，但是固态分区的盘符是G，且可以感觉到相应的软件还是从C盘启动的。那这个固态几乎只是个摆设，显然不是我想要的。 过程这里折腾的过程没时间记录了，直接上成功的流程： 分区助手（傲梅），找到系统迁移，按提示进行，这里好像用到了PreOS。 老毛桃PE(Windows8.1)，找到引导修复工具，首先将G盘和C盘的盘符互相修改，即G改为C，C改为G，点击修复；其次点击自动修复BCD删除多余项目。 分区助手（Genius），将C盘取消激活，给SSD重建引导，激活相应的盘符。 总结折腾这些是因为不想重装系统重新安装之前收集的软件，这些折腾是重启了几十遍才完成的，还有很多次强关机。下次要想不折腾，弄清楚再完成整个流程。]]></content>
      <categories>
        <category>PC</category>
      </categories>
      <tags>
        <tag>PC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[释怀]]></title>
    <url>%2FPoetry%2F%E9%87%8A%E6%80%80.html</url>
    <content type="text"><![CDATA[唏嘘成愁 唯黄昏而思烛明 唯覆雪始念日暖唯放手方知情真 今困苦而怀峥嵘今飘零而涌乡愁 今孑然而徒唏嘘 var ap = new APlayer({ element: document.getElementById("aplayer-osAOFtqh"), narrow: false, autoplay: false, showlrc: false, music: { title: "Let Her Go", author: "Passenger", url: "https://music.163.com/song/media/outer/url?id=18161816.mp3", pic: "", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap);]]></content>
      <categories>
        <category>Poetry</category>
      </categories>
      <tags>
        <tag>Lyric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python曲线平滑处理]]></title>
    <url>%2FPython%2FPython%E6%9B%B2%E7%BA%BF%E5%B9%B3%E6%BB%91%E5%A4%84%E7%90%86.html</url>
    <content type="text"><![CDATA[背景在用Python画函数图形时发现曲线不平滑，百度发现解决方案核心思想是插值法，即将定义域的取值点增加到原来的100倍甚至以上，即可达到曲线平滑的目的。所以仅仅需要增加取值点的个数。 代码示例1234567891011121314151617181920212223# quantitative genetics homeworkimport numpy as npimport matplotlib.pyplot as pltplt.title("Effect of selection on gene frequency for different initial frequencies")plt.xlabel("Frequency of A2")plt.ylabel("Δq")q = np.arange(0, 1.01, 0.01)#真实取值点个数为（1.01-0）/0.01qt = np.arange(0, 1.1, 0.1)#x轴画出的单位长度为0.1，范围在（0, 1.0），1.1不取plt.xticks(qt)#途中所展示单位长度p = 1 - qs = 0.2Q1 = s*q**2*(1-q)/(1-s*(1-q**2))plt.plot(q, Q1)Q2 = p*q*(s*p-s*q)/(1-s*p**2-s*q**2)plt.plot(q, Q2)y = np.arange(-0.023, 0.035, 0.002)plt.yticks(y)plt.grid()plt.show() 图像展示 参考Python如何对折线进行平滑曲线处理？]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缺少库libssl.so和libcrypto.so]]></title>
    <url>%2FLinux%2F%E7%BC%BA%E5%B0%91%E5%BA%93libssl.so%E5%92%8Clibcrypto.so.html</url>
    <content type="text"><![CDATA[起因服务器上安装Aria2需要这两个库，网上检索到仅需要安装openssl即可，但是尝试后并没成功。 1$ conda install openssl=1.0 解决方案 最后找到原因：~/.condarc中源的顺序很讲究： 1234channels: - conda-forge - bioconda - defaults 另外还有一种解决方案：找到更高版本的库，然后在需要的目录中创建软连接，且名字改为aria2需要的版本。 1$ ln -s xx/xx/libcrypto.so.1.x.x libcrypto.so.1.0.0 查依赖库1$ ldd $(which aria2) 参考samtools 1.9 dependency pulls in wrong version of openssl pacman: error while loading shared libraries: libssl.so.0.9.8]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>报错解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pychrm pro 2019.1下载安装及永久破解]]></title>
    <url>%2FPC-Tools%2FPycharm.html</url>
    <content type="text"><![CDATA[前言近期需要安装Pycharm，有强迫症要安装最新版本，又想要永久破解。学习了好久，终于成功了。还是激活码给力，其他的地方也有新的发现。 下载安装点我下载内含安装包，注册码，语言包。 安装根据自己需要安装，到最后点我稍后重启； 注册码不用其中的，用这个： 1D00F1BDTGF-eyJsaWNlbnNlSWQiOiJEMDBGMUJEVEdGIiwibGljZW5zZWVOYW1lIjoiaHR0cHM6Ly96aGlsZS5pbyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiJVbmxpbWl0ZWQgbGljZW5zZSB0aWxsIGVuZCBvZiB0aGUgY2VudHVyeS4iLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IklJIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiV1MiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJEQiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlJNIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiRE0iLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IkdPIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUFMiLCJwYWlkVXBUbyI6IjIwODktMDctMDcifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjA4OS0wNy0wNyJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In0seyJjb2RlIjoiUlNVIiwicGFpZFVwVG8iOiIyMDg5LTA3LTA3In1dLCJoYXNoIjoiODkwNzA3MC8wIiwiZ3JhY2VQZXJpb2REYXlzIjowLCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-3OPFIX9/KSL76ctAKOwpBPCCAfUhUbucdNbtqMaTqRryvKEvrFqCKncE0eMHA2YkrcP2CtV9LKjlIXhJMqp0N821Qv1AhuIJrDMBubqiEtiqnGkcGV35DF0GzyUQaUdN6fTbZna05riHzR6yzgEzo9R3RIzCTDMQdB/0EojWM0nCBkPsLdncZeDv3+Y+VA8ZH3/BBvzwR1e0gWsT3mfT9tIvwxPuEhNrQFNOP1PZOjC8nX9h/J7ag5X3JQL1CQVi4TnEipdy0fxKbDPKTloM3Y/bA23uaW+Q/JQFBRKRR0q3FYJ1DQuSc7YmeJ7Q2IHq7u5QYz8jPZJtP6PKs6g/tQ==-MIIECDCCAfCgAwIBAgIJAI5/xwNtz47cMA0GCSqGSIb3DQEBCwUAMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0EwIBcNMTgwODIzMDcwNDA3WhgPMjExODA3MzAwNzA0MDdaMBExDzANBgNVBAMMBnByb2QzeTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOZ3WopNRg9J8k3apGYFEUGRlvkRsQnQSEz1yMKY4YWg9ElxmuF0mQRAaIj3WOl1eqTn1CXsn4vXV7GODJk9A/rCqEk960sPesWn/RVz7zo5+KazE3Y9yYtwskKxlnkFNp82Kha6dUGDSwG2lYh0Sria2ByOhgr6gmyXtC0PKqlIlTAPcBvz0MEnKTZkxfSqdiHo/meTlMRd9885vr4P52Fd9Ryxe3yVAKZSP9ZzPmRvCvgF1oGCgobZJ5d7FvTwkGt2t4pjy/RlU6FDcXNMHLk4pfJqr3lnEkAh2MbCGlGo1i6Rc6DtgISuJn2AUkrQKhI6F0U7o9e5qPEOjNkhznMCAwEAAaNaMFgwCQYDVR0TBAIwADALBgNVHQ8EBAMCBaAwHQYDVR0OBBYEFJDgSMx4XrLktYOG827wP7VULTnJMB8GA1UdIwQYMBaAFDAS51akWaJlzxC2x4yP3iAYbqtxMA0GCSqGSIb3DQEBCwUAA4ICAQBxRyfCpL7q2VurGfh9XqaC4GsGp6ut3l/rOEyc6DP148A69DRmZ7saqfZW87DcLkmcynPhyBOxdcGwtwKlR9E/+X923JeL6VPQCTY5WyJKib36vQCnoC4ELTnw1yc51v2j+MaZXjrlzBIcCUocWK14WS4iBycUwLuMszz6rJ8xluuYDKDeNcS/AjQf+yTUfDXjktHLgcE27sSEQUQ+7bpbKHkJ5xBvaupJEPX+ndj7V2eD+/sO03jgnsWVa2nky7yDXX/5KCqzL5kAA1n2t2dWSJXxpac8O2bPyRhk6dUSwzNr+IjCjHqUKIouB0nosi85Q5MaIE0pwOOSggnawpnjmL3qDnsS/n7NUcX/mF4eiNQ8cMJmKIgfS6rntKuQY2zSod+4+G0AFbiihVTnKsRf7CiJa/VniZdaGdbclT8KzRnNKJ1TrPO8rVPjg+SpvqTq75xynS08/OXCpoJ3aVeBWZJYJmheHhvJw2RiNW2P2GSIw+m6HIIsthUtvvHqdKpIaThFHAOKmw0LpPO7uGs/z/Q3un7+lqSlW7akUoSCHdiAJ4wWv+qFEgE4mq8bKtHoa9yy6FZBoORbbRTj8WkS+UvCLN5p7kZenmKYnWCzBf02O1ULpMsR5WvKCGCekSwWf3lAF9lYTL12JaFTw9iH1nSkyvcu7AoXlWI50hOhmA== 汉化语言包放在Pycharm的安装目录下，默认的是C:\Program Files\JetBrains\PyCharm 2019.1\lib。 注意自己的安装路径 破解补丁链接: https://pan.baidu.com/s/1yNGyJGtcmzED-aoGye7Qhg 提取码: kbt9将它放在C:\Program Files\JetBrains\PyCharm 2019.1\bin下。把其中的pycharm64.exe.vmoptions末尾添加一行： 1-javaagent:C:\Program Files\JetBrains\PyCharm 2019.1\bin\JetbrainsCrack-release-enc.jar 注意自己的安装路径 破解顺序 正常安装 放入破解补丁，改pycharm64.exe.vmoptions文件 屏蔽检测：在C:\Windows\System32\drivers\etc\HOSTS末尾添加（文本编辑器打开）123#pycharm0.0.0.0 account.jetbrains.com0.0.0.0 www.jetbrains.com 在命令提示符中输入ipconfig /flushdns刷新。 打开在Activate code填入上方的注册码 结果这样一来，可以用到2089年。说不定可以送走一些人，哈哈哈哈哈哈 参考1.Pycharm2019.1永久激活2.pycharm 2019中文破解版 新的发现有的激活码可能用不了多久，或者已经终止授权，此处可以利用屏蔽效果来截断授权的验证以达到激活成功的目的。即点击激活的同时将hosts更改且刷新DNS。]]></content>
      <categories>
        <category>PC Tools</category>
      </categories>
      <tags>
        <tag>Pycharm pro 2019.1</tag>
        <tag>永久破解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPKM、FPKM和TPM]]></title>
    <url>%2FBioinfomatics%2FRPKM%E3%80%81FPKM%E5%92%8CTPM.html</url>
    <content type="text"><![CDATA[前言在重复Nature Prtocol的RNAseq流程中看到了FPKM，就想起来了这三个概念。现在把它们分辨清楚。 定义RPKM：Reads per kilobase of exon per million reads mapped；每一百万比对的reads中，其中外显子的每一千个碱基中reads的条数。FPKM：Fragments per kilobase of exon per million reads mapped；每一百万比对的fragments中，其中外显子的每一千个碱基中fragments的条数，注意其中将比对到一个fragment上的两个reads计算一次。TPM：Transcripts per million reads。每一百万条reads中转录本的个数。 计算过程因为在对基因或者转录本标准化的过程中，基因长度和测序深度影响较大。RPKM和FPKM都是先将测序深度标准化，即每个样本的每个基因的reads count数同时除以总的样本各自的总reads count数。再进行基因长度的标准化，将上一步得到的结果除以该基因的长度即可。TPM的计算类似，但是计算顺序不同，先除以该基因的长度，即先进行基因长度的标准化，再除以标准化后的总reads count数，即后进行测序深度的标准化。此处可以得到，RPKM和FPKM在进行标准化后的每个样本的reads count之和并不完全相等。而TPM的每个样本的reads count之和是相等的，可以直接用作比较。现在很多软件可以直接处理原始的reads count，有的则只能处理RPKM/FPKM。注意分辨。 参考RNA-Seq分析|RPKM, FPKM, TPM, 傻傻分不清楚？RPKM vs FPKM vs TPM]]></content>
      <categories>
        <category>Bioinfomatics</category>
      </categories>
      <tags>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Aria2满速下载神器]]></title>
    <url>%2FPC%2F%E6%90%AD%E5%BB%BAAria2%E6%BB%A1%E9%80%9F%E4%B8%8B%E8%BD%BD%E7%A5%9E%E5%99%A8.html</url>
    <content type="text"><![CDATA[前言恰逢新装百兆宽带，无奈下载的资源仍然被限速，尤其是遇到某盘的资源。更是焦头烂额。早听闻Aria2可以完全发挥宽带潜能，但无奈搭建还是有几分复杂（其实我懒）。前几日耐着性子把它搭建好。 本地配置点击下载这是官方资源，然后选择自己的版本。需要在aria2c.exe所在目录中新建aria2.conf、aria2.session和Star.bat文件，新建download目录。 aria.conf文件参照这里设置。 aria2.session保持为空文件即可，不能启动Aria2时，删除重建。 Star.bat内容如下： 1aria2c.exe --conf=aria2.conf 需要隐藏CMD窗口新建HideRun.vbs，内容为： 1CreateObject(&quot;WScript.Shell&quot;).Run &quot;aria2c.exe的完整路径 --conf-path=aria2.conf&quot;,0 最好将下载的资源放在分区根目录，且重命名为aria2，不然容易出现未知的不能搭建的错误。 WebGUI配置这里有现成的已汉化控制台：http://aria2c.com 使用方法 双击Star.bat 打开 http://aria2c.com ，在其中添加下载任务 浏览器插件BaiduExporter：将百度云盘资源添加到Aria2下载任务中。下载器：将浏览器下载任务转移到Aria2 参考aria2使用教程Aria2 &amp; YAAW 使用说明]]></content>
      <categories>
        <category>PC</category>
      </categories>
      <tags>
        <tag>Download Tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNA-seq数据初步分析流程1]]></title>
    <url>%2FRNA-seq%2FRNA-seq%E6%95%B0%E6%8D%AE%E5%88%9D%E6%AD%A5%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B1.html</url>
    <content type="text"><![CDATA[前言花了四个月左右时间做的毕设，到现在才有时间（其实我懒）记录过程。]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>Mapping</tag>
        <tag>Differential expression analysis</tag>
        <tag>Enrichment analysis</tag>
        <tag>KOBAS</tag>
        <tag>Fastp</tag>
        <tag>Quality control</tag>
        <tag>HTSeq</tag>
        <tag>Count reads</tag>
        <tag>TopHat2</tag>
        <tag>Cufflinks</tag>
        <tag>DESeq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HISAT2报错解决]]></title>
    <url>%2FRNA-seq%2FHISAT2%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3.html</url>
    <content type="text"><![CDATA[报错信息： Error while flushing and closing outputterminate called recursivelyterminate called after throwing an instance of ‘int’(ERR): hisat2-align died with signal 6 (ABRT) (core dumped) Error:Encountered internal HISAT2 exception (#1) 原因及解决方案： 硬盘不足，腾出空间即可，或者先把hisat2的已经运行完整的sam文件转为bam文件，可节约空间。 遇到此类报错，原因是输入了不能识别的参数，包括空格（多、少）、符号（短横线、双短横线、逗号等）。请仔细检查命令行的输入。]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>报错解决</tag>
        <tag>HISAT2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用IGV判断测序是否为链特异性测序]]></title>
    <url>%2FRNA-seq%2F%E5%88%A9%E7%94%A8IGV%E5%88%A4%E6%96%AD%E6%B5%8B%E5%BA%8F%E6%98%AF%E5%90%A6%E4%B8%BA%E9%93%BE%E7%89%B9%E5%BC%82%E6%80%A7%E6%B5%8B%E5%BA%8F.html</url>
    <content type="text"><![CDATA[起因在学习RNA-seq的过程中，用以前的（2015年左右）生物信息分析流程的tophat和htseq等软件，需要在参数中指出建库类型，否则对结果产生较大的影响。 检索通过百度，检索到可以用IGV基因组浏览器来鉴别 下载安装点击进入下载页面按个人情况选择平台进行安装 使用准备准备好自己所研究物种的参考基因组文件（xx.fa）、注释文件（xx.gtf/gff）和已经比对完成的bam文件。 载入文件先载入基因组：Genomes &gt; Load Genome from File &gt; 选定基因组文件注意：可能需要建立索引，按文字指示操作就行 载入注释文件：File &gt; Load from File &gt; 选定排序后的注释文件注意：可能需要建立索引，按文字指示操作就行。必须要通过IGVtools排序，一样按文字指示操作 载入bam文件：File &gt; Load from File &gt; 选定bam文件注意：bam文件需要用 samtools index xx.bam来操作在同级目录下生成xx.bam.bai后才能被IGV浏览到此文件载入完成。 选择合适位置查看Tips（仅供像我一样的新手参考）：只需要放大倍数增大到正在查看的染色体区域有2500bp左右的倍数即可（仅供参考），或者是注释文件中的基因恰好能有一到两个在窗口之中即可按顺序达到如下步骤：上图按照igv 颜色选项中的read strand 方向进行区分，可以看到所有红色read都是在正链方向（注意正链不是正义链），而所有蓝色的read都是负链方向。可以看到同一个gene相关的read颜色还是混杂的，因为它并不是链特异性文库，所以不能分开first strand和second strand。如果是链特异性建库、测序会出现： 参考1.链特异性测序及在IGV中的可视结果2.用IGV判断NGS链特异性3.链特异建库那点事]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>IGV</tag>
        <tag>library type</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samtools0.19和HTSeq0.6.1p1报错的解决方案]]></title>
    <url>%2FRNA-seq%2FSamtools0.19%E5%92%8CHTSeq0.6.1p1%E6%8A%A5%E9%94%99%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html</url>
    <content type="text"><![CDATA[起因因学习需要，使用 samtools 0.19和HTSeq0.6.1p1，遇上几个不常见的报错信息。特做记录。 类别 samtools sort乱码表现：终端在最后完成排序后不断输出乱码原因：0.19版本的samtools没有添加 -o 选项，现在的教程都添加了这个参数。解决方案：去掉 -o 参数，直接接排序完成的文件名前缀（除.bam之外的部分） HTSeq 0.6.1p1计数报错1报错信息：Warning: Read HWI-D00523:166:C7106ANXX:1:2104:4424:74281 claims to have an aligned mate which could not be found in an adjacent line.原因：tophat2的结果默认按染色体位置排序，而没有按read name排序，HTSeq检测到了孤立的read（在双端数据中）解决方案：htseq之前用samtools按reads排序 HTSeq 0.6.1p1计数报错2Error occured when processing SAM input (record #210 in file accepted_hits.bam):‘pair_alignments’ needs a sequence of paired-end alignments原因：htseq-count generally deals well with the orphaned reads (it just issues a warning, since how these should be handled is a bit ambiguous in the specification), but I wonder if mixing paired and single-end data in one file leads to this sort of error (in fact, looking through the source code suggests that that’s the only circumstance that can lead to this).【3】解决方案：对bam文件进行过滤【4】双端：samtools view -bf 1 foo.bam &gt; foo.paired-end.bam单端：samtools view -bF 1 foo.bam &gt; foo.single-end.bam 参考1.生信小白的RNA-seq实战历程2.被忽视的Samtools参数3.34.4]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>report imformation</tag>
        <tag>Samtools</tag>
        <tag>HTSeq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用指令（更新中）]]></title>
    <url>%2FLinux%2FLinux%20%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4.html</url>
    <content type="text"><![CDATA[起因学校服务器linux版本过低，想安装生物信息学软件未果，但在折腾过程中学到很过新的指令，记录在此以免忘记。 查看当前工作目录(完整路径) pwd -P 列出当前目录所有文件和目录 ls 返回上级目录 cd .. 返回上一次的目录 cd - 返回用户根目录 cd 创建新目录 mkdir ** 删除文件/目录 rm ** 解压 xx.gz gunzip xx.gz 查看命令使用文档 man 命令 绝对路径 /root/xx/ 相对路径 ./xxx 创建多层目录 mkdir -p xx/xx/xx 删除空目录 rmdir xx 移动文件到目录下 mv file dir 更改目录名 mv dir1 dir2 查看文件内容 cat xx # 从第一行顺序显示文件内容tac xx # 从最后一行倒序显示文件内容 创建f1到f3的软连接 ln -s f1 f3 关于环境变量 export PATH=/xx/xx:$PATH # 临时添加，终端关闭后失效 vi ~/.bashrc末尾追加export PATH=”/xx/xx:$PATH” # 当前用户生效 vi /etc/profile末尾追加export PATH=”/xx/xx:$PATH”source /etc/profile # 所有用户 export PATH=$PATH:路径1:路径2:路径n$PATH表示之前所有设置的路径,不加入则失去之前设置的路径 查找文件 find /xx -name ** # 可以结合正则表达式 关于vi vi是linux自带编辑器，直接在终端使用，方法 vi xx 进入vi后，是在命令模式，输入i到输入模式，输入:到底行命令模式，在输入模式下按Esc才能切换模式 底行命令模式中，q表示退出，w表示保存，！表示强制]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Server</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[During 12.22-12.24]]></title>
    <url>%2FPoetry%2F12.22-12.24%E6%9C%89%E6%84%9F%E8%80%8C%E5%86%99%E7%9A%84%E8%AF%97.html</url>
    <content type="text"><![CDATA[路途所感 瞥高山流水 噫仙雾缭绕于魔音灌耳 感思绪飞扬间始觉故里 房屋几座农家人余忆吾幼年 终日嬉戏无劳神他乡苦寒窗数载 师承先德苦栽培不知学子才尚浅 搁至此久得空闲绒雪纷飞不觉寒 道过中途迫遣返早知落雪差池生 何须改日把家还 var ap = new APlayer({ element: document.getElementById("aplayer-JkjZmDSy"), narrow: false, autoplay: false, showlrc: false, music: { title: "Let Her Go", author: "Passenger", url: "https://music.163.com/song/media/outer/url?id=18161816.mp3", pic: "", lrc: "" } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap);]]></content>
      <categories>
        <category>Poetry</category>
      </categories>
      <tags>
        <tag>Sentiment</tag>
        <tag>Record</tag>
        <tag>Memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Enrichment analysis of GO & KEGG]]></title>
    <url>%2FRNA-seq%2FGO%26KEGG%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%94%A8KOBAS%E8%BF%9B%E8%A1%8C%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90.html</url>
    <content type="text"><![CDATA[前言GO是Gene ontology的缩写，是一系列用来描述基因、基因产物特性的语义（terms）。KEGG（ Kyoto Encyclopedia of Genes and Genomes），是一个系统分析基因产物在细胞中代谢途径的数据库，是一种最常用的代谢通路分析。 介绍GO是Gene ontology的缩写，是一系列用来描述基因、基因产物特性的语义（terms）。这些语义主要分为三种：细胞组份（Cellular Component，简称 GO-CC），用于描述基因产物在细胞中的位置，如内质网，核或蛋白酶体等；分子功能(Molecular Function，简称 GO-MF)，大部分指的是单个基因产物的功能，如结合活性或催化活性等。 生物学途径/过程 (biological process，简称 GO-BP)，多是指具有多个步骤的有序的生物过程，如细胞生长、分化和维持、凋亡以及信号传导等过程。 Pathway指代谢通路，对差异基因进行pathway分析，可以知道实验条件下哪些代谢通路发生显著改变。KEGG（ Kyoto Encyclopedia of Genes and Genomes），是一个系统分析基因产物在细胞中代谢途径的数据库，是一种最常用的代谢通路分析。 在线分析分析方式有很多，例如：神包 clusterProfiler，DAVID，KOBAS，webgestalt这里分别使用 KOBAS 和 webgestalt KOBASKOBAS 输入id：选择 id 类型、输入物种、输入id： 选择分析类型： 结果： 查看： 我点击通路名称时，得到404，可能是偶然因素 Webgestalt选择物种、分析方式、数据库、输入 ID 类型、参考序列 分析方式 ORA 或者 GSEA当选择数据库为 pathway，再选 KEGG 时，可做 KEGG 通路富集分析参考序列可自定义上传 参考 GO KEGG数据库用法 | 基因集功能注释 | 代谢通路富集 零基础的小白如何自己做GO/KEGG分析？ GO、KEGG富集分析——DAVID与KOBAS在线分析工具 推荐神包：clusterProfiler包做GO分析]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>Enrichment analysis</tag>
        <tag>KOBAS</tag>
        <tag>Webgestalt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Differential expression analysis -- DESeq2]]></title>
    <url>%2FRNA-seq%2FDESeq2%E6%A6%82%E8%BF%B0.html</url>
    <content type="text"><![CDATA[前言DESeq2 是一款基于负二项分布的R包，对于 count data 进行处理，用于 RNA-seq 基因差异分析。 安装RGUI中输入： 123if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;)BiocManager::install(&quot;DESeq2&quot;, version = &quot;3.8&quot;) 矩阵准备1. 载入表达矩阵表达矩阵的数据结构： gene 列为基因 ensemble_id，后几个列名为样本名称，中间为 count（次数） 2. 设置分组信息分组信息的结构： id 列为样本名称，后几列的列名为因素 核心步骤1.载入数据123456789101112131415161718192021222324252627options(stringsAsFactors = FALSE)# 载入 count 文件（由 htseq-count 计数，未标准化），sep 指定分隔符，col.names 指定列名# 一个因素：种类 bec 和 lyec，三个生物学重复ten &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/E10_count.txt&quot;, sep=&quot;\t&quot;, col.names = c(&quot;gene_id&quot;,&quot;bec1&quot;))ele &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/E11_count.txt&quot;, sep=&quot;\t&quot;, col.names = c(&quot;gene_id&quot;,&quot;bec2&quot;))fif &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/E15_count.txt&quot;, sep=&quot;\t&quot;, col.names = c(&quot;gene_id&quot;,&quot;bec3&quot;))six &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/E16_count.txt&quot;, sep=&quot;\t&quot;, col.names = c(&quot;gene_id&quot;,&quot;lyec1&quot;))eig &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/E18_count.txt&quot;, sep=&quot;\t&quot;, col.names = c(&quot;gene_id&quot;,&quot;lyec2&quot;))thi &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/E13_count.txt&quot;, sep=&quot;\t&quot;, col.names = c(&quot;gene_id&quot;,&quot;lyec3&quot;))# 合并各个表达矩阵，一次性合并报错了（估计是行数不统一问题）all &lt;- merge(ten, ele, by=&quot;gene_id&quot;)all &lt;- merge(all, fif, by=&quot;gene_id&quot;)all &lt;- merge(all, six, by=&quot;gene_id&quot;)all &lt;- merge(all, eig, by=&quot;gene_id&quot;)all &lt;- merge(all, thi, by=&quot;gene_id&quot;)# 把 ensemble_id 作为行号rownames(all) &lt;- all[,1]# 把 ensemble_id 列删除，因为已经由行号来表示all = all[,-1]# 删除整行 count 皆为零的行all = all[rowSums(all) &gt;0,]# 删除 count 文件最后五行的结果统计all = all[-1,]all = all[-1,]all = all[-1,]all = all[-1,]all = all[-1,] 设置分组信息1234# rep 指定生物学重复数condition &lt;- factor(c(rep(&quot;bec&quot;,3),rep(&quot;lyec&quot;,3)), levels = c(&quot;bec&quot;,&quot;lyec&quot;))# 创建 colDatacolData &lt;- data.frame(row.names=colnames(all), condition) 构建 dds（DESeqDataSet）12345# 载入包library(DESeq2)# 构建 ddsdds &lt;- DESeqDataSetFromMatrix(all, colData, design= ~ condition)dds &lt;- DESeq(dds) 结果123456789res= results(dds) # 或者 res = results(dds, contrast=c(&quot;condition&quot;, &quot;bec&quot;, &quot;lyec&quot;))# 根据 p-value 排序res = res[order(res$pvalue),]# 显示一共多少个 genes 上调和下调（FDR0.1）summary(res)# 保存为文件write.csv(res,file=&quot;All_results.csv&quot;)# padj小于0.05的 genestable(res$padj&lt;0.05) 提取差异基因1234# padj&lt;0.05 且 表达倍数取以2为对数后大于1或者小于-1的差异表达基因diff_gene_deseq2 &lt;-subset(res, padj &lt; 0.05 &amp; abs(log2FoldChange) &gt; 1)# 保存差异表达基因的结果write.csv(diff_gene_deseq2,file= &quot;DEGs_BEC_vs_LYEC.csv&quot;) gene symbol 注释123456789101112131415# 载入包，没安装的百度包名，进入 Bioconductor 安装library(&apos;biomaRt&apos;)library(&quot;curl&quot;)# 重新载入差异表达基因，head=T：将首行作为列名DEG &lt;- read.table(&quot;E:/RNA-SEQ/4.0deseq/DEGs_BEC_vs_LYEC.csv&quot;, sep=&quot;,&quot;, head = T)# 查看有哪些数据库可用ensembl=useMart(&quot;ensembl&quot;)# 查看需要用到的物种的数据集listDatasets(ensembl) # ggallus_gene_ensembl：鸡的数据集，数据库选择 ensemblemart &lt;- useDataset(&quot;ggallus_gene_ensembl&quot;, useMart(&quot;ensembl&quot;))# 将 id 赋值给 my_ensembl_gene_idmy_ensembl_gene_id&lt;-DEG[,1]# 注释结果gg_symbols&lt;- getBM(attributes=c(&apos;ensembl_gene_id&apos;,&apos;external_gene_name&apos;,&quot;description&quot;),filters = &apos;ensembl_gene_id&apos;, values = my_ensembl_gene_id, mart = mart) 合并差异基因和注释结果被合并的两个表要有共同的列和列名 1234# 按 ensembl_gene_id 合并，如果表不大可用 Excel 插入共同的列和列名DEG_ann&lt;-merge(DEG,gg_symbols,by=&quot;ensembl_gene_id&quot;)# 将合并结果保存为文件write.csv(DEG_ann,file= &quot;DEGs_BEC_vs_LYEC_ANN.csv&quot;) 下游分析GO 和 KEGG 富集分析（也可以有蛋白网络互作分析） 参考 RNA-seq(7): DEseq2筛选差异表达基因并注释(bioMart) 简单使用DESeq2/EdgeR做差异分析 Bioconductor:DESeq2 RNA_seq分析流程软件思维导图]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>Differential expression analysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gene expression levels analysis -- HTSeq-count]]></title>
    <url>%2FRNA-seq%2FHTSeq-count%E6%A6%82%E8%BF%B0.html</url>
    <content type="text"><![CDATA[前言HTSeq 是一款针对于有参考基因组的，分析高通量测序数据的Python库。官网： HTSeq 安装HTSeq作为Python库推荐采用pip安装方式： 1pip install htseq 还能采用源码安装、conda安装、apt-get等 使用1htseq-count [options] &lt;alignment_file&gt; &lt;gtf_file&gt; 这里的 alignment file 可以是 bam 或者 sam 文件 上游准备 已排序的比对文件： sam 或者 bam 文件 排序要求建议按 reads name 排序 计数模型：union, intersection-strict and intersection-nonempty 测序的建库工作是否为链特异性建库，一般不是 参数 type 和 idattr 的确定，非 Ensemble 的注释文件这两个参数尚待明确，知道的麻烦告知一下，提前感谢！下游适配HTSeq 的计数结果没有进行标准化，因为我下游分析是采用 DESeq2，不需要标准化常用参数1234567891011# 命令参数-f | --format default: sam 设置输入文件的格式，该参数的值可以是sam或bam。-r | --order default: name 设置sam或bam文件的排序方式，该参数的值可以是name或pos。前者表示按read名进行排序，后者表示按比对的参考基因组位置进行排序。若测序数据是双末端测序，当输入sam/bam文件是按pos方式排序的时候，两端reads的比对结果在sam/bam文件中一般不是紧邻的两行，程序会将reads对的第一个比对结果放入内存，直到读取到另一端read的比对结果。因此，选择pos可能会导致程序使用较多的内存，它也适合于未排序的sam/bam文件。而pos排序则表示程序认为双末端测序的reads比对结果在紧邻的两行上，也适合于单端测序的比对结果。很多其它表达量分析软件要求输入的sam/bam文件是按pos排序的，但HTSeq推荐使用name排序，且一般比对软件的默认输出结果也是按name进行排序的。-s | --stranded default: yes 设置是否是链特异性测序。该参数的值可以是yes,no或reverse。no表示非链特异性测序；若是单端测序，yes表示read比对到了基因的正义链上；若是双末端测序，yes表示read1比对到了基因正义链上，read2比对到基因负义链上；reverse表示双末端测序情况下与yes值相反的结果。根据说明文件的理解，一般情况下双末端链特异性测序，该参数的值应该选择reverse（本人暂时没有测试该参数）。-a | --a default: 10 忽略比对质量低于此值的比对结果。在0.5.4版本以前该参数默认值是0。-t | --type default: exon 程序会对该指定的feature（gtf/gff文件第三列）进行表达量计算，而gtf/gff文件中其它的feature都会被忽略。-i | --idattr default: gene_id 设置feature ID是由gtf/gff文件第9列那个标签决定的；若gtf/gff文件多行具有相同的feature ID，则它们来自同一个feature，程序会计算这些features的表达量之和赋给相应的feature ID。-m | --mode default: union 设置表达量计算模式。该参数的值可以有union, intersection-strict and intersection-nonempty。这三种模式的选择请见上面对这3种模式的示意图。从图中可知，对于原核生物，推荐使用intersection-strict模式；对于真核生物，推荐使用union模式。-o | --samout 输出一个sam文件，该sam文件的比对结果中多了一个XF标签，表示该read比对到了某个feature上。-q | --quiet 不输出程序运行的状态信息和警告信息。-h | --help 输出帮助信息。 批量化处理借助bash： 123456789#!/bin/bashfor i in 10 11; do &#123; htseq-count -f bam -s no in/E$&#123;i&#125;.sorted.bam\ anno/Gallus_gallus.Gallus_gallus-5.0.94.gtf &gt; out/E$&#123;i&#125;_count.txt &#125;;donewait 此处参考基因组来自于 Ensemble，而 -t 和 -i 在采用 Ensemble 的注释文件时默认为：exon 和 gene_id 输出结果文件为： 1234567891011121314151617181920212223head counts.txtENSG00000000003 0ENSG00000000005 0ENSG00000000419 1171ENSG00000000457 563ENSG00000000460 703ENSG00000000938 0ENSG00000000971 1ENSG00000001036 925ENSG00000001084 1468ENSG00000001167 2997 tail count.txtENSG00000283696 18ENSG00000283697 0ENSG00000283698 1ENSG00000283699 0ENSG00000283700 0__no_feature 3469791__ambiguous 630717__too_low_aQual 1346501__not_aligned 520623__alignment_not_unique 2849422 下游分析需要将其合并到一个文件中，一个行为基因名，列为样本名，中间为 count 的行列式文件。这里也可以将其中 count 为零的行删除。所以应该是先合并、再删除计数全为零的行。 参考 RNA-seq分析htseq-count的使用 RNA-seq流程分析比较之半小时得到差异基因 转录组入门(6)： reads计数 官网]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>count reads</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mapping -- HISAT2]]></title>
    <url>%2FRNA-seq%2FHISAT2%E6%A6%82%E8%BF%B0.html</url>
    <content type="text"><![CDATA[前言针对一般人类群体（以及有参考基因组的群体），HISAT2是一种快速灵敏的比对程序，用于绘制第二代测序序列（全基因组，转录组和外显子组测序数据）。是有参转录组常用的比对软件（无参常用bowtie2），HISAT2是TopHat2/Bowtie2的继任者，使用改进的BWT算法，实现了更快的速度和更少的资源占用。 官网：HISAT2 下载安装 源码编译 下载：Source code 解压 hisat2-2.1.0-source.zip 切换到解压目录 编译：目录下 make 将 HISAT2 加入环境变量 二进制文件 下载：Binary（Linux_x86_64） 解压 hisat2-2.1.0-Linux_x86_64.zip，包含下面用到的文件（hisat2、xx.py、hisat2-build等） 建立索引需要参考序列（注释文件）。先建立基因组、转录组、SNP的索引文件，再建立其索引（以下代码在终端中运行，注意你的参考基因组等文件存放位置可能与我不同）。 建立基因组的索引文件： 12cd hisat2-2.1.0-Linux_x86_64extract_exons.py Homo_sapiens.GRCh38.83.chr.gtf &gt; genome.exon 建立转录组的索引文件： 1extract_splice_sites.py Homo_sapiens.GRCh38.83.chr.gtf &gt; genome.ss 建立SNP的索引文件： 1extract_snps.py snp142Common.txt &gt; genome.snp 建立索引： 1hisat2-build -p 4 genome.fa --snp genome.snp --ss genome.ss --exon genome.exon genome_snp_tran -p 指定线程数，genome_snp_tran 为索引的名称在第四步时，如果没有前三步会自动建立起 exon、snp、splice sites 文件及其索引，但是提前建立会提高分析效率前三步在过程中会占用一定的磁盘空间，我的磁盘空间有所不足，所以我选择直接采用第四步，有条件的尽量。所以注释文件可不下载 比对1hisat2 -p 16 -x ./grch38_tran/genome_tran -1 SRR534293_1.fastq -2 SRR534293_2.fastq –S SRR534293.sam 注： -p 线程数。-1 fastq文件，-2 另一端fastq文件（支持gzip文件）。-S 输出的SAM文件。 结合samtoolsHISAT2通过管道符（|）与samtools结合，将HISAT2输出的SAM文件排序、转化为BAM文件，加速分析流程、节约硬盘空间 12hisat2 -p 4 -x index/genome -1 in/out.E10_1.fq.gz -2 in/out.E10_2.fq.gz | samtools sort -n -o \out/E10.sorted.bam 批量化处理借助bash，批量化处理 123456789#!/bin/bashfor i in 10 11; do &#123; hisat2-2.1.0/hisat2 -p 4 -x index/genome -1 in/out.E$&#123;i&#125;_1.fq.gz -2 in/out.E$&#123;i&#125;_2.fq.gz \ | samtools sort -n -o out/E$&#123;i&#125;.sorted.bam &#125;;donewait 参考 官网：HISAT2 比对软件hisat2的使用 HISAT2-StringTie-Ballgown有参转录组数据分析 RNA-seq(5):序列比对：Hisat2]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>Mapping</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Quality control -- Fastp]]></title>
    <url>%2FRNA-seq%2FFastp%E6%A6%82%E8%BF%B0.html</url>
    <content type="text"><![CDATA[前言Fastp是一款旨在提供FastQ文件快速的一体化预处理工具。由C语言开发且支持多线程的高性能表现。 官方文档：Fastp in GitHubFastp文章链接：https://www.biorxiv.org/content/early/2018/03/01/274100 功能特点 对数据自动进行全方位质控，生成人性化的报告 过滤功能（低质量，太短，太多N……） 对每一个序列的头部或尾部，计算滑动窗内的质量均值，并将均值较低的子序列进行切除（类似Trimmomatic的做法，但是快非常多） 全局剪裁 （在头/尾部，不影响去重），对于Illumina下机数据往往最后一到两个cycle需要这样处理 去除接头污染。厉害的是，你不用输入接头序列，因为算法会自动识别接头序列并进行剪裁 对于双端测序（PE）的数据，软件会自动查找每一对read的重叠区域，并对该重叠区域中不匹配的碱基对进行校正 去除尾部的polyG。对于Illumina NextSeq/NovaSeq的测序数据，因为是两色法发光，polyG是常有的事，所以该特性对该两类测序平台默认打开 对于PE数据中的overlap区间中不一致的碱基对，依据质量值进行校正 可以对带分子标签（UMI）的数据进行预处理，不管UMI在插入片段还是在index上，都可以轻松处理 可以将输出进行分拆，而且支持两种模式，分别是指定分拆的个数，或者分拆后每个文件的行数 更多查看官方文档 注意： 默认已经开启一些功能，也可关闭或者改变mo某个功能的默认参数 支持gzip输入与输出 支持SE（single end）和PE（paired end）数据 完美支持short reads和一定程度的long reads 生成html和json报告，且可动态交互（html预览 json预览） 下载安装官方文档介绍了三种获得Fastp的方式： Install with Bioconda (may be not the lastest version) 1conda install -c bioconda fastp Download binary (only for Linux system, http://opengene.org/fastp/fastp) This binary was compiled on CentOS, and tested on CentOS/Ubuntu (测试于Ubuntu 18.04 &amp; 16.04可用) 12wget http://opengene.org/fastp/fastpchmod a+x ./fastp Compile from sourceGet source (you can also use browser to download from master or releases) 123456git clone https://github.com/OpenGene/fastp.git# buildcd fastpmake# Installsudo make install 我选择二进制文件，可直接按如下代码使用，无需安装 1./fastp [option] 简单使用SE数据： 1fastp -i in.fq -o out.fq 输入需要过滤、质控和预处理的fastq文件（in.fq）输出clean data（out.fq）、报告文件（fast.html和fastp.json）报告文件名称可通过 -h xx.html 和 -j xx.json 更改 PE数据： 1fastp -i in.R1.fq -o out.R1.fq -I in.R2.fq -O out.R2.fq 注意： o与O是小写字母o与大写字母O gzip数据的输入无需参数，自动按后缀识别（xx.gz）例：1fastp -i in.R1.fq.gz -I in.R2.fq.gz -o out.R1.fq.gz -O out.R2.fq.gz 精确使用具体参数的使用、调节都需要根据具体的质控要求及项目或者文章结果要求进行更改。附上全部参数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495usage: fastp -i &lt;in1&gt; -o &lt;out1&gt; [-I &lt;in1&gt; -O &lt;out2&gt;] [options...]options: # I/O options -i, --in1 read1 input file name (string) -o, --out1 read1 output file name (string [=]) -I, --in2 read2 input file name (string [=]) -O, --out2 read2 output file name (string [=]) -6, --phred64 indicate the input is using phred64 scoring (it&apos;ll be converted to phred33, so the output will still be phred33) -z, --compression compression level for gzip output (1 ~ 9). 1 is fastest, 9 is smallest, default is 4. (int [=4]) --stdin input from STDIN. If the STDIN is interleaved paired-end FASTQ, please also add --interleaved_in. --stdout output passing-filters reads to STDOUT. This option will result in interleaved FASTQ output for paired-end input. Disabled by default. --interleaved_in indicate that &lt;in1&gt; is an interleaved FASTQ which contains both read1 and read2. Disabled by default. --reads_to_process specify how many reads/pairs to be processed. Default 0 means process all reads. (int [=0]) --dont_overwrite don&apos;t overwrite existing files. Overwritting is allowed by default. # adapter trimming options -A, --disable_adapter_trimming adapter trimming is enabled by default. If this option is specified, adapter trimming is disabled -a, --adapter_sequence the adapter for read1. For SE data, if not specified, the adapter will be auto-detected. For PE data, this is used if R1/R2 are found not overlapped. (string [=auto]) --adapter_sequence_r2 the adapter for read2 (PE data only). This is used if R1/R2 are found not overlapped. If not specified, it will be the same as &lt;adapter_sequence&gt; (string [=]) --detect_adapter_for_pe by default, the adapter sequence auto-detection is enabled for SE data only, turn on this option to enable it for PE data. # global trimming options -f, --trim_front1 trimming how many bases in front for read1, default is 0 (int [=0]) -t, --trim_tail1 trimming how many bases in tail for read1, default is 0 (int [=0]) -b, --max_len1 if read1 is longer than max_len1, then trim read1 at its tail to make it as long as max_len1. Default 0 means no limitation (int [=0]) -F, --trim_front2 trimming how many bases in front for read2. If it&apos;s not specified, it will follow read1&apos;s settings (int [=0]) -T, --trim_tail2 trimming how many bases in tail for read2. If it&apos;s not specified, it will follow read1&apos;s settings (int [=0]) -B, --max_len2 if read2 is longer than max_len2, then trim read2 at its tail to make it as long as max_len2. Default 0 means no limitation. If it&apos;s not specified, it will follow read1&apos;s settings (int [=0]) # polyG tail trimming, useful for NextSeq/NovaSeq data -g, --trim_poly_g force polyG tail trimming, by default trimming is automatically enabled for Illumina NextSeq/NovaSeq data --poly_g_min_len the minimum length to detect polyG in the read tail. 10 by default. (int [=10]) -G, --disable_trim_poly_g disable polyG tail trimming, by default trimming is automatically enabled for Illumina NextSeq/NovaSeq data # polyX tail trimming -x, --trim_poly_x enable polyX trimming in 3&apos; ends. --poly_x_min_len the minimum length to detect polyX in the read tail. 10 by default. (int [=10]) # per read cutting by quality options -5, --cut_by_quality5 enable per read cutting by quality in front (5&apos;), default is disabled (WARNING: this will interfere deduplication for both PE/SE data) -3, --cut_by_quality3 enable per read cutting by quality in tail (3&apos;), default is disabled (WARNING: this will interfere deduplication for SE data) -W, --cut_window_size the size of the sliding window for sliding window trimming, default is 4 (int [=4]) -M, --cut_mean_quality the bases in the sliding window with mean quality below cutting_quality will be cut, default is Q20 (int [=20]) # quality filtering options -Q, --disable_quality_filtering quality filtering is enabled by default. If this option is specified, quality filtering is disabled -q, --qualified_quality_phred the quality value that a base is qualified. Default 15 means phred quality &gt;=Q15 is qualified. (int [=15]) -u, --unqualified_percent_limit how many percents of bases are allowed to be unqualified (0~100). Default 40 means 40% (int [=40]) -n, --n_base_limit if one read&apos;s number of N base is &gt;n_base_limit, then this read/pair is discarded. Default is 5 (int [=5]) # length filtering options -L, --disable_length_filtering length filtering is enabled by default. If this option is specified, length filtering is disabled -l, --length_required reads shorter than length_required will be discarded, default is 15. (int [=15]) --length_limit reads longer than length_limit will be discarded, default 0 means no limitation. (int [=0]) # low complexity filtering -y, --low_complexity_filter enable low complexity filter. The complexity is defined as the percentage of base that is different from its next base (base[i] != base[i+1]). -Y, --complexity_threshold the threshold for low complexity filter (0~100). Default is 30, which means 30% complexity is required. (int [=30]) # filter reads with unwanted indexes (to remove possible contamination) --filter_by_index1 specify a file contains a list of barcodes of index1 to be filtered out, one barcode per line (string [=]) --filter_by_index2 specify a file contains a list of barcodes of index2 to be filtered out, one barcode per line (string [=]) --filter_by_index_threshold the allowed difference of index barcode for index filtering, default 0 means completely identical. (int [=0]) # base correction by overlap analysis options -c, --correction enable base correction in overlapped regions (only for PE data), default is disabled --overlap_len_require the minimum length of the overlapped region for overlap analysis based adapter trimming and correction. 30 by default. (int [=30]) --overlap_diff_limit the maximum difference of the overlapped region for overlap analysis based adapter trimming and correction. 5 by default. (int [=5]) # UMI processing -U, --umi enable unique molecular identifier (UMI) preprocessing --umi_loc specify the location of UMI, can be (index1/index2/read1/read2/per_index/per_read, default is none (string [=]) --umi_len if the UMI is in read1/read2, its length should be provided (int [=0]) --umi_prefix if specified, an underline will be used to connect prefix and UMI (i.e. prefix=UMI, UMI=AATTCG, final=UMI_AATTCG). No prefix by default (string [=]) --umi_skip if the UMI is in read1/read2, fastp can skip several bases following UMI, default is 0 (int [=0]) # overrepresented sequence analysis -p, --overrepresentation_analysis enable overrepresented sequence analysis. -P, --overrepresentation_sampling One in (--overrepresentation_sampling) reads will be computed for overrepresentation analysis (1~10000), smaller is slower, default is 20. (int [=20]) # reporting options -j, --json the json format report file name (string [=fastp.json]) -h, --html the html format report file name (string [=fastp.html]) -R, --report_title should be quoted with &apos; or &quot;, default is &quot;fastp report&quot; (string [=fastp report]) # threading options -w, --thread worker thread number, default is 2 (int [=2]) # output splitting options -s, --split split output by limiting total split file number with this option (2~999), a sequential number prefix will be added to output name ( 0001.out.fq, 0002.out.fq...), disabled by default (int [=0]) -S, --split_by_lines split output by limiting lines of each file with this option(&gt;=1000), a sequential number prefix will be added to output name ( 0001.out.fq, 0002.out.fq...), disabled by default (long [=0]) -d, --split_prefix_digits the digits for the sequential number padding (1~10), default is 4, so the filename will be padded as 0001.xxx, 0 to disable padding (int [=4]) # help -?, --help print this message 我的项目的质控要求： 去除接头（对于双端已自动去除，无需参数） 去除含N比例大于0.1的 reads（参数 -n 的默认值为5，我的测序reads 长125bp，则 -n 应为12.5≈13） 去除低质量 reads（Q phred &lt;= 20 的碱基数占整个 read 长度的 50％以上的 reads）（-q 20 -u 50） 速度尽可能快：线程数：-w 4（CPU：双核四线程） 注意： 线程数根据CPU能力调节 质控要求所对应的参数调节具体查看官方文档 批量化处理数据时，可写出相应 bash 脚本： 12345678for i in 10 11; do &#123; ./fastp -i raw/E$&#123;i&#125;_1.fq.gz -I raw/E$&#123;i&#125;_2.fq.gz\ -o out/out.E$&#123;i&#125;_1.fq.gz -O out/out.E$&#123;i&#125;_2.fq.gz\ -q 20 -u 50 -n 13 -w 4 -h out/E$&#123;i&#125;.html -j out/E$&#123;i&#125;.json &#125;;donewait 注意： 这里的 raw 和 out 是我创建的文件夹，便于管理 bash 语法自行学习使用 参考 官方文档 生信工具Fastp的安装及其在二代测序数据过滤质控中的使用说明 使用fastp进行数据质控 fastp: 一款超快速全功能的FASTQ文件自动化质控+过滤+校正+预处理软件]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
      <tags>
        <tag>Fastp</tag>
        <tag>Quality control</tag>
      </tags>
  </entry>
</search>
